
<details>
<summary>Коммуникация и поддержка</summary>

<details>
<summary>Email классификатор</summary>

```mermaid
flowchart LR
    A["Email получен"] --> B["Классификатор писем"]
    B -->|Не спам| C["Валидатор: может ли LLM ответить?"]
    B -->|Спам| D["Переместить в корзину"]
    C -->|Сложный ответ| E["Human's assistance"]
    C -->|Простой ответ| F["Генерация ответа"]
    F --> G["Отправить Email"]
    E --> G
```

<details>
<summary>Примеры входных запросов</summary>

```text
Email 1:
От: client@example.com
Тема: Проблема с оплатой
Сообщение: "Здравствуйте, я оплатил заказ несколько дней назад, но статус не изменился. Помогите, пожалуйста."

Email 2:
От: user2@example.com
Тема: Вопрос о продукте
Сообщение: "Добрый день, расскажите, пожалуйста, о возможностях вашего приложения."
```
</details>

<details>
<summary>Системный промпт: Классификатор писем</summary>

```text
Вы — модель, которая классифицирует входящие письма как 'spam' или 'not_spam'.
Получаете на вход заголовок и тело письма.
Выход — одно слово: 'spam' или 'not_spam'.
```
</details>

<details>
<summary>Системный промпт: Валидатор (может ли LLM ответить?)</summary>

```text
Вы — модель, проверяющая, может ли LLM автономно ответить на запрос.
Получаете тело письма.
Если ответ прост — выведите 'simple_answer', иначе 'complex_answer'.
```
</details>

<details>
<summary>Системный промпт: Генерация ответа</summary>

```text
Вы — помощник службы поддержки. Составьте вежливый и лаконичный ответ клиенту на основе текста письма:
\"\"\"{email_body}\"\"\"
```
</details>

</details>

<details>
<summary>Триаж запросов в службу поддержки</summary>

```mermaid
flowchart LR
    Request[Сообщение клиента] --> Intent[Классификация intent]
    Intent -->|FAQ| FAQSearch[Поиск в БД FAQ]
    Intent -->|Тех. поддержка| Human[К оператору]
    FAQSearch --> Answer[LLM: генерация ответа]
    Answer --> Send[Отправка ответа клиенту]
    Human --> Send
```

<details>
<summary>Примеры входных запросов</summary>

```text
Запрос 1: "Как сбросить пароль к аккаунту?"
Запрос 2: "У меня ошибка при оплате подписки, номер заказа #12345."
```
</details>

<details>
<summary>Системный промпт: Классификация intent</summary>

```text
Вы — модель, которая на основе сообщения клиента определяет intent: 'FAQ' или 'technical_support'.
Выход — 'FAQ' или 'technical_support'.
```
</details>

<details>
<summary>Системный промпт: LLM генерация ответа по FAQ</summary>

```text
Вы — помощник, генерирующий ответ на основе найденного FAQ.
Вход: запрос клиента и контент FAQ:
\"\"\"Вопрос: {faq_question}
Ответ: {faq_answer}\"\"\"
Выход — полный ответ клиенту.
```
</details>

</details>

</details>
<details>
<summary>Суммаризация документов</summary>

<details>
<summary>Пайплайн суммаризации документов</summary>

```mermaid
flowchart LR
    Doc[Загруженный документ] --> Split[Разбиение на части]
    Split --> PartSummary[LLM: суммаризация частей]
    PartSummary --> Merge[Агрегация итогов]
    Merge --> Final[ReturnFinalAnswer]
```

<details>
<summary>Примеры входных документов</summary>

```text
Документ 1: Статья о JavaScript (≈ 5 000 токенов)
Документ 2: Отчет по продажам за квартал (≈ 8 000 токенов)
```

</details>

<details>
<summary>Системный промпт: LLM — суммаризация частей</summary>

```text
Вы — модель для суммаризации текстовых фрагментов.
Ваша задача — на основе входного фрагмента (≤ 6000 токенов) сформировать краткую и информативную сводку (≤ 500 токенов).
Вход: текстовый фрагмент документа.
Выход: сводка фрагмента.
```

</details>

</details>

<details>
<summary>Суммаризация бесконечного текста</summary>

Допустим, вы можете использовать только LLM, которая максимально вмещает 8000 токенов в свои Attention-слои. Максимально LLM может генерировать до 2000 токенов. (Итого: 6000 токенов input, 2000 output)

```mermaid
flowchart LR
    Doc[Исходный документ около 400 000 токенов] --> Split[Разбиение по 6000 токенов]
    Split --> Summarize[LLM: суммирует каждую часть до 2000 токенов]
    Summarize --> Merge[Объединение промежуточных сводок]
    Merge --> Decision{Длина сводки > 2000 токенов?}
    Decision -->|Да| Split
    Decision -->|Нет| Final[Итоговая сводка ≤ 2000 токенов]
```

Например, для текста в 18 мегатокенов, алгоритм отработает в 2 цикла суммаризации:
    1. 1 цикл: 18 000 токенов -> 6 000 токенов
        1.1. 18 000 токенов -> 3 чанка по 6 000 токенов
        1.2. 3 чанка по 6 000 токенов -> 3 саммари по 2 000 токенов
        1.3. 3 саммари по 2 000 токенов -> конкатенация в 1 сводку в 6 000 токенов
    2. 2 цикл: 6 000 токенов -> 2 000 токенов
        2.1. 6 000 токенов -> 1 чанк по 6 000 токенов
        2.2. 1 чанк по 6 000 токенов -> 1 саммари по 2 000 токенов
        2.3. 1 саммари по 2 000 токенов -> финальная сводка

<details>
<summary>Примеры входного документа</summary>

```text
Документ: Техническая спецификация продукта (≈ 400 000 токенов)
```

</details>

<details>
<summary>Системный промпт: LLM — суммирует каждую часть до 2000 токенов</summary>

```text
Суммаризируй текст в 2000 токенов.
```

</details>

</details>

<details>
<summary>Анализ и обработка большого текста с логикой менеджера</summary>

```mermaid
flowchart LR
    U[Логика обработки от пользователя] --> Process
    Doc[Большой текст] --> Split[Разбиение на чанки]
    Split --> Process[LLM: обработка каждого чанка]
    Process --> Merge[Агрегация результатов]
    Merge --> Final[ReturnFinalAnswer]
```

<details>
<summary>Примеры входных данных</summary>

```text
Логика обработки: "Найдите все упоминания слов 'ошибка' и 'исключение', подсчитайте их частоту."
Текст: Логи приложения (≈ 100 000 токенов)
```

</details>

<details>
<summary>Системный промпт: LLM — обработка текстового чанка</summary>

```text
Вы — аналитическая модель. Ваша задача — на основе заданной логики пользователя и входного текстового чанка сформировать частичный отчёт.
Вход:
- Логика обработки: {логика}
- Текст чанка: {текст}
Выход:
- Частичный отчёт.
```

</details>

</details>

</details>

<details>
<summary>Социальный мониторинг и рекомендации</summary>

<details>
<summary>Мониторинг социальных сетей</summary>

```mermaid
flowchart LR
    Fetch[Сбор постов] --> Sentiment[LLM: анализ тональности]
    Sentiment -->|Негатив| Alert[Уведомление команде]
    Sentiment -->|Нейтрально/Позитивно| Schedule[План публикации]
    Schedule --> Publish[Публикация поста]
```

<details>
<summary>Примеры входных запросов</summary>

```text
Запрос 1: "Собрать последние 100 твитов с хэштегом #нашПродукт"
Запрос 2: "Получить посты из Instagram за последние 24 часа с упоминанием бренда"
```
</details>

<details>
<summary>Пример системного промпта для шага "анализ тональности"</summary>

```text
Вы — модель анализа тональности социальных медиа. Ваша задача — классифицировать каждый пост как «Негативный», «Нейтральный» или «Позитивный».
Входные данные:
- Текст поста: {текст}
Выходные данные:
- Тональность: {Негативный|Нейтральный|Позитивный}
- Краткое обоснование классификации.
```
</details>

</details>

<details>
<summary>Рекомендательная система</summary>

```mermaid
flowchart LR
    Profile[Профиль пользователя] --> Embed[Генерация эмбеддингов]
    Embed --> Retrieve[Поиск похожих товаров]
    Retrieve --> Recommend[LLM: генерация рекомендаций]
    Recommend --> Display[Отображение рекомендаций]
```

<details>
<summary>Примеры входных данных</summary>

```text
Профиль пользователя:
- ID: 12345
- История просмотров: ["Телефон", "Наушники", "Чехлы"]
- Возраст: 29
- Интересы: технологии, музыка
```

</details>

<details>
<summary>Пример системного промпта для шага "генерация рекомендаций"</summary>

```text
Вы — система рекомендаций на основе LLM. Ваша задача — на основе эмбеддингов пользователя и списка похожих товаров сформировать пять релевантных рекомендаций.
Входные данные:
- Эмбеддинги пользователя: {vector}
- Список похожих товаров: [{id, название, эмбеддинг}, ...]
Выходные данные:
- JSON-массив с рекомендациями:
[
  {id: ..., название: ..., причина: ...},
  ...
]
```

</details>

</details>

</details>


<details>
<summary>Код-ревью и публикация</summary>

  <details>
  <summary>Автоматизированный код-ревью</summary>

  ```mermaid
  flowchart LR
      PR[Pull Request] --> Lint[Автоматические тесты]
      Lint -->|Ошибки| Report[Формирование отчёта]
      Lint -->|ОК| Comments[LLM: генерация комментариев]
      Comments --> Post[Добавить комментарии в PR]
  ```

  <details>
  <summary>Примеры входных запросов</summary>

  ```text
  Запрос 1: Pull Request с изменениями в файле app.js:
  ```diff
  - function add(a, b) { return a + b; }
  + function add(a, b) { return Number(a) + Number(b); }
  ```
  Запрос 2: Pull Request, удаляющий неиспользуемые переменные в utils.js:
  ```diff
  - const unused = 42;
  + // удалено
  ```
  ```
  </details>

  <details>
  <summary>Системный промпт: LLM — генерация комментариев</summary>

  ```text
  Вы — ассистент по автоматизированному code review. 
  Ваша задача — на основе diff Pull Request:
  - обнаружить синтаксические или логические ошибки,
  - отметить нарушения стайлгайда,
  - предложить рекомендации по улучшению кода.
  Входные данные:
  - diff Pull Request: {diff}
  Выходной формат (structured output):
  [
    {file: "app.js", line: 1, comment: "Рекомендуется явно приводить параметры к Number для безопасного сложения строк."},
    {file: "utils.js", line: 3, comment: "Переменная 'unused' не используется — стоит её удалить."}
  ]
  ```
  </details>

  </details>

  <details>
  <summary>Публикация блога</summary>

  ```mermaid
  flowchart LR
      Draft[Черновик статьи] --> SpellCheck[LLM: проверка орфографии]
      SpellCheck --> StyleEdit[LLM: улучшение стиля]
      StyleEdit --> Publish[Публикация в соц. сетях]
  ```

  <details>
  <summary>Примеры входных запросов</summary>

  ```text
  Черновик статьи:
  "OpenAI представила новую модель GPT-4. Она предлагает улучшенные возможности для генерации текста, поддержки кода и аналитики данных. Некоторые участки текста можно сделать более плавными и выразительными..."
  ```
  </details>

  <details>
  <summary>Системный промпт: LLM — проверка орфографии</summary>

  ```text
  Вы — модель для орфографической проверки текстов. 
  Ваша задача — найти и исправить опечатки и типографические ошибки.
  Вход:
  - текст черновика: {draft_text}
  Выход:
  - исправленный текст без ошибок.
  ```
  </details>

  <details>
  <summary>Системный промпт: LLM — улучшение стиля</summary>

  ```text
  Вы — модель для стилистического редактирования текстов. 
  Ваша задача — сделать текст более плавным, ясным и привлекательным, сохранив исходный смысл.
  Вход:
  - текст после орфографической правки: {corrected_text}
  Выход — отредактированный текст.
  ```
  </details>

  </details>

</details>

<details>
<summary>Маркетинг и продажи</summary>

  <details>
  <summary>Персонализация маркетинговой кампании</summary>

  ```mermaid
  flowchart LR
      CRM[Данные клиентов] --> Segment[LLM: сегментация аудитории]
      Segment --> Message[LLM: генерация сообщений]
      Message --> Launch[Запуск e‑mail кампании]
  ```

  <details>
  <summary>Примеры входных запросов</summary>

  ```text
  CRM данные 1: {id: 101, имя: "Анна", возраст: 28, последние_покупки: ["кроссовки","футболка"], интересы: ["спорт","путешествия"]}
  CRM данные 2: {id: 102, имя: "Борис", возраст: 35, последние_покупки: ["смарт‑часы"], интересы: ["технологии","фитнес"]}
  ```
  </details>

  <details>
  <summary>Системные промпты</summary>

    <details>
    <summary>LLM: сегментация аудитории</summary>

    ```text
    Вы — модель, которая на основе списка CRM-данных сегментирует клиентов по категориям (возраст, интересы, история покупок).
    Вход: список клиентов [{id, имя, возраст, последние_покупки, интересы}, ...]
    Выход — JSON-массив сегментов:
    [
      {segment_id: 1, критерии: "спортсмены 25-35", клиенты: [101, ...]},
      ...
    ]
    ```
    </details>

    <details>
    <summary>LLM: генерация сообщений</summary>

    ```text
    Вы — копирайтер-помощник, создающий персонализированные e-mail для каждого сегмента.
    Вход: сегмент {segment_id, критерии, клиенты} и шаблон сообщения.
    Выход — JSON-массив сообщений:
    [
      {segment_id: 1, subject: "Специальное предложение для спортсменов", body: "..."},
      ...
    ]
    ```
    </details>

  </details>

  </details>

  <details>
  <summary>Квалификация лидов и upsale (Sales)</summary>

  ```mermaid
  flowchart LR
      Lead[Новый лид] --> Qualify[LLM: квалификация]
      Qualify -->|Готов к продаже| Propose[LLM: коммерческое предложение]
      Propose --> Send[Отправка предложения]
      Send --> Follow[LLM: анализ ответов]
      Follow -->|Положительный| Upsell[LLM: генерация upsale]
      Upsell --> SendUpsell[Отправка доп. предложения]
  ```

  <details>
  <summary>Примеры входных запросов</summary>

  ```text
  Лид 1: {id: "LID123", компания: "Acme Corp", бюджет: 50000, потребность: "CRM-система"}
  Лид 2: {id: "LID124", компания: "Beta LLC", бюджет: 150000, потребность: "аналитика продаж"}
  ```
  </details>

  <details>
  <summary>Системные промпты</summary>

    <details>
    <summary>LLM: квалификация</summary>

    ```text
    Вы — модель, оценивающая лиды по готовности к покупке.
    Вход: лид {id, компания, бюджет, потребность}
    Выход — {lead_id, status: "готов"/"не готов", score: число}
    ```
    </details>

    <details>
    <summary>LLM: коммерческое предложение</summary>

    ```text
    Вы — помощник по продажам, генерирующий коммерческие предложения.
    Вход: лид {lead_id, компания, потребность, бюджет} и шаблон КП.
    Выход — {lead_id, proposal: "текст коммерческого предложения"}
    ```
    </details>

    <details>
    <summary>LLM: анализ ответов</summary>

    ```text
    Вы — модель для анализа отзывов клиентов.
    Вход: переписка {lead_id, сообщения: [...]}
    Выход — {lead_id, sentiment: "положительный"/"отрицательный"/"нейтральный"}
    ```
    </details>

    <details>
    <summary>LLM: генерация upsale</summary>

    ```text
    Вы — ассистент по upsell, формирующий дополнительное предложение.
    Вход: лид {lead_id} и история взаимодействий.
    Выход — {lead_id, upsell_offer: "текст дополнительного предложения"}
    ```
    </details>

  </details>

  </details>

</details>

<details>
<summary>Операционные процессы</summary>

<details>
<summary>Автоматическая дозакупка товаров</summary>

```mermaid
flowchart LR
    SalesData[Данные по продажам] --> Forecast[LLM: прогноз спроса]
    Forecast --> OrderGen[LLM: генерация заказа]
    OrderGen --> SendOrder[Отправка заказа поставщику]
```

<details>
<summary>Примеры входных данных</summary>

```json
{
  "sales_data": [
    {"product_id": "A1", "date": "2024-06-01", "quantity": 120},
    {"product_id": "B2", "date": "2024-06-01", "quantity": 75}
  ],
  "safety_stock": 50
}
```

</details>

<details>
<summary>Системные промпты</summary>

<details>
<summary>LLM: прогноз спроса</summary>

```text
Вы — модель прогнозирования спроса.
Вход: массив записей о продажах с полями {product_id, date, quantity}.
Задача: на основе исторических данных предсказать спрос на каждый товар на следующий период.
Выход: массив объектов [{product_id, forecast_quantity}, ...].
```

</details>

<details>
<summary>LLM: генерация заказа</summary>

```text
Вы — ассистент по формированию заказов поставщику.
Вход: прогноз спроса [{product_id, forecast_quantity}, ...] и параметр безопасности (safety_stock).
Задача: рассчитать количество заказа, чтобы покрыть прогнозный спрос плюс запас.
Выход: массив объектов [{product_id, order_quantity}, ...].
```

</details>

</details>

</details>

<details>
<summary>Проверка соответствия документов</summary>

```mermaid
flowchart LR
    DocReview[Документ на проверку] --> Extract[LLM: выделение ключевых пунктов]
    Extract --> ComplianceCheck[LLM: оценка соответствия правилам]
    ComplianceCheck --> ReportGen[Формирование отчёта]
    ReportGen --> Approval[Утверждение ответственным]
```

<details>
<summary>Примеры входных данных</summary>

```text
Тип документа: договор аренды  
Текст документа:  
"Настоящий договор заключён между Арендодателем и Арендатором...
Статья 1. Предмет договора...
Статья 2. Срок действия..."
```

</details>

<details>
<summary>Системные промпты</summary>

<details>
<summary>LLM: выделение ключевых пунктов</summary>

```text
Вы — модель для извлечения ключевых пунктов из юридического текста.
Вход: полный текст документа.
Задача: выделить номера статей и их краткое содержание.
Выход: массив объектов [{article: номер, summary: текст}, ...].
```

</details>

<details>
<summary>LLM: оценка соответствия правилам</summary>

```text
Вы — модель проверки соответствия документа заданным нормативам.
Вход: массив ключевых пунктов и список правил.
Задача: для каждого пункта определить, соответствует ли он правилам.
Выход: [{article, compliance: "соответствует"/"не соответствует", comments}, ...].
```

</details>

<details>
<summary>LLM: формирование отчёта</summary>

```text
Вы — помощник по подготовке отчётов.
Вход: результаты оценки соответствия.
Задача: сгенерировать структурированный отчёт в markdown с разделами «Соответствующие пункты» и «Нарушения».
Выход: markdown-текст отчёта.
```

</details>

</details>

</details>

</details>

<details>
<summary>HR-процессы</summary>

<details>
<summary>Скрининг резюме (Recruitment)</summary>

```mermaid
flowchart LR
    Applicants[Поток резюме] --> Parser[LLM: парсинг резюме]
    Parser --> Score[LLM: оценка кандидатов]
    Score --> Filter{Проходит порог?}
    Filter -->|Да| Interview[Назначение интервью]
    Filter -->|Нет| Reject[Отправить отказ]
    Interview --> Scheduler[Автоматизация календаря]
    Scheduler --> Done[Уведомление кандидату]
```

<details>
<summary>Примеры входных данных</summary>

```json
[
  {
    "name": "Иван Иванов",
    "skills": ["Python", "SQL", "Docker"],
    "experience_years": 3,
    "education": "Магистр компьютерных наук"
  },
  {
    "name": "Анна Петрова",
    "skills": ["Java", "Spring", "Microservices"],
    "experience_years": 5,
    "education": "Бакалавр ИТ"
  }
]
```

</details>

<details>
<summary>Системные промпты</summary>

<details>
<summary>LLM: парсинг резюме</summary>

```text
Вы — модель для структурирования резюме.
Вход: текст резюме.
Задача: извлечь {name, skills, experience_years, education}.
Выход: JSON-объект с полями кандидата.
```

</details>

<details>
<summary>LLM: оценка кандидатов</summary>

```text
Вы — модель для оценки резюме по заданным критериям.
Вход: объект {name, skills, experience_years}.
Критерии: релевантность навыков и стаж работы.
Выход: {name, score: число от 0 до 100}.
```

</details>

<details>
<summary>LLM: назначение интервью</summary>

```text
Вы — ассистент по планированию интервью.
Вход: список кандидатов, прошедших порог, и доступные слоты интервью.
Задача: распределить кандидатов по слотам.
Выход: [{name, interview_time}, ...].
```

</details>

</details>

</details>

<details>
<summary>Автоматизация онбординга (HR)</summary>

```mermaid
flowchart LR
    NewHire[Новый сотрудник] --> Docs[LLM: подготовка документов]
    Docs --> Setup[LLM: инструкции по IT и доступам]
    Setup --> Training[План обучения]
    Training --> Feedback[Сбор обратной связи]
    Feedback --> HR[Уведомление HR]
```

<details>
<summary>Примеры входных данных</summary>

```json
{
  "name": "Сергей Кузнецов",
  "position": "Frontend-разработчик",
  "start_date": "2024-07-01"
}
```

</details>

<details>
<summary>Системные промпты</summary>

<details>
<summary>LLM: подготовка документов</summary>

```text
Вы — помощник HR для подготовки корпоративных документов.
Вход: {name, position, start_date}.
Задача: сформировать список и шаблоны документов (трудовой договор, NDA и т.д.).
Выход: [{document_type, template_text}, ...].
```

</details>

<details>
<summary>LLM: инструкции по IT и доступам</summary>

```text
Вы — модель по генерации инструкций для настройки IT-среды.
Вход: должность сотрудника.
Задача: создать чек-лист по созданию учетных записей и настройке ПО.
Выход: список пунктов чек-листа.
```

</details>

<details>
<summary>LLM: план обучения</summary>

```text
Вы — ассистент по обучению новых сотрудников.
Вход: должность.
Задача: разработать пошаговый план обучения с модулями и сроками.
Выход: [{module, duration_days}, ...].
```

</details>

<details>
<summary>LLM: сбор обратной связи</summary>

```text
Вы — модель для генерации анкеты обратной связи.
Вход: список этапов онбординга.
Задача: сформулировать вопросы для каждого этапа.
Выход: [{stage, questions: [...]}, ...].
```

</details>

<details>
<summary>LLM: уведомление HR</summary>

```text
Вы — помощник для уведомления HR об итогах.
Вход: результаты обратной связи.
Задача: составить краткое сообщение с ключевыми выводами.
Выход: текст уведомления.
```

</details>

</details>

</details>

</details>

<details>
<summary>DevOps</summary>

<details>
<summary>CICD pipeline мониторинг</summary>

```mermaid
flowchart LR
    Commit[Коммит] --> Build[Сборка проекта]
    Build -->|Ошибка| Analyze[LLM: анализ логов]
    Analyze --> Report[Отчёт об ошибках]
    Report --> Notify[Уведомление команды]
    Build -->|Успех| Deploy[Деплой в staging]
    Deploy --> Test[Запуск автотестов]
    Test -->|Ошибка| AnalyzeTest[LLM: анализ результатов]
    AnalyzeTest --> ReportTest[Отчёт о проблемах]
    ReportTest --> Notify
    Test -->|Успех| Done[Успешный деплой]
```

<details>
<summary>Примеры входных данных</summary>

```text
Коммит: {id: "abc123", author: "ivan", timestamp: "2024-06-15T10:23:00Z"}
Логи сборки: "ERROR: Module not found: 'utils.js'"
```
</details>

<details>
<summary>Примеры системных промптов</summary>

<details>
<summary>LLM: анализ логов</summary>

```text
Вы — модель для анализа логов CI. Вход: текст логов сборки. Задача: найти причину ошибки и предложить решение. Выход: {error_type, message, recommendation}.
```
</details>

<details>
<summary>LLM: анализ результатов</summary>

```text
Вы — модель для анализа результатов автотестов. Вход: вывод тестового раннера. Задача: выявить упавшие тесты и описать проблему. Выход: [{test_name, status: "fail"/"pass", log}].
```
</details>

</details>
</details>

<details>
<summary>Автотесты: генерация и анализ</summary>

```mermaid
flowchart LR
    Code[Изменения в коде] --> TestGen[LLM: генерация автотестов]
    TestGen --> Run[Запуск тестов]
    Run --> Analyze[LLM: анализ результатов]
    Analyze --> Report[Формирование отчёта]
    Report --> Notify[Уведомление разработчика]
```

<details>
<summary>Примеры входных данных</summary>

```text
Изменения в коде: diff функции sum(a, b)
Результаты тестов: 3 passed, 1 failed (test_sum.js)
```
</details>

<details>
<summary>Примеры системных промптов</summary>

<details>
<summary>LLM: генерация автотестов</summary>

```text
Вы — ассистент по генерации автотестов. Вход: diff кода. Задача: сгенерировать unit-тесты на Jest для новых или изменённых функций. Выход: код тестов.
```
</details>

<details>
<summary>LLM: анализ результатов</summary>

```text
Вы — модель для анализа результатов тестов. Вход: вывод тест-раннера. Задача: выделить упавшие тесты и предложить варианты фиксации. Выход: [{test_name, status, suggestion}].
```
</details>

</details>
</details>

</details>

<details>
<summary>Прочие кейсы</summary>

<details>
<summary>Генерация квизов для обучения</summary>

```mermaid
flowchart LR
    Material[Учебный материал] --> QuizGen[LLM: генерация вопросов]
    QuizGen --> Review[LLM: проверка качества]
    Review --> Format[Форматирование квиза]
    Format --> Publish[Публикация для участников]
```

<details>
<summary>Примеры входных данных</summary>

```text
Учебный материал: "Основы HTTP: методы GET/POST, статус-коды"
```
</details>

<details>
<summary>Примеры системных промптов</summary>

<details>
<summary>LLM: генерация вопросов</summary>

```text
Вы — модель для генерации учебных вопросов. Вход: текст материала. Задача: сформулировать 5 вопросов разных типов (открытые, с выбором). Выход: [{question, type}].
```
</details>

<details>
<summary>LLM: проверка качества</summary>

```text
Вы — модель для оценки качества вопросов. Вход: список вопросов. Задача: проверить корректность формулировок и сложность. Выход: [{question, ok: true/false, comment}].
```
</details>

</details>
</details>

<details>
<summary>Автоматизация отчётов по расходам</summary>

```mermaid
flowchart LR
    Transactions[Данные транзакций] --> Extract[LLM: выделение расходов]
    Extract --> Categorize[LLM: категоризация]
    Categorize --> Summary[Формирование отчёта]
    Summary --> Approve[Утверждение]
    Approve --> Done[Отправка отчёта]
```

<details>
<summary>Примеры входных данных</summary>

```json
{
  "transactions": [
    {"id": "T1", "amount": 250},
    {"id": "T2", "amount": 75}
  ]
}
```
</details>

<details>
<summary>Примеры системных промптов</summary>

<details>
<summary>LLM: выделение расходов</summary>

```text
Вы — модель для извлечения данных о расходах. Вход: массив транзакций. Задача: вернуть список {id, amount}.
```
</details>

<details>
<summary>LLM: категоризация</summary>

```text
Вы — модель для классификации расходов. Вход: список {id, amount}. Задача: присвоить категорию из списка. Выход: [{id, category}].
```
</details>

</details>
</details>

<details>
<summary>Персональный планировщик путешествий</summary>

```mermaid
flowchart LR
    Preferences[Параметры поездки] --> Plan[LLM: план маршрута]
    Plan --> Book[Генерация бронирований]
    Book --> Itinerary[Форматирование плана]
    Itinerary --> Send[Отправка путешественнику]
```

<details>
<summary>Примеры входных данных</summary>

```json
{
  "destination": "Барселона",
  "dates": ["2024-07-01", "2024-07-07"],
  "preferences": ["музеи", "пляж"]
}
```
</details>

<details>
<summary>Примеры системных промптов</summary>

<details>
<summary>LLM: план маршрута</summary>

```text
Вы — ассистент по планированию путешествий. Вход: параметры поездки. Задача: предложить маршрут по дням. Выход: [{day, activities}].
```
</details>

<details>
<summary>LLM: генерация бронирований</summary>

```text
Вы — модель для формирования бронирований. Вход: маршрут. Задача: сгенерировать данные для брони отеля и транспорта. Выход: [{service, details}].
```
</details>

<details>
<summary>LLM: форматирование плана</summary>

```text
Вы — помощник по форматированию плана. Вход: данные бронирований и маршрут. Задача: собрать единый документ с расписанием. Выход: markdown.
```
</details>

</details>
</details>

</details>

<details>
<summary>Маршрутизация запросов на четыре направления</summary>

```mermaid
flowchart LR
    Request[Входящий запрос клиента] --> Router[LLM routing]
    Router -->|Продажи| Sales[Отдел продаж]
    Router -->|Техническая поддержка| Tech[Отдел техподдержки]
    Router -->|Биллинг| Billing[Отдел биллинга]
    Router -->|Общие вопросы| General[Общий отдел]
    Sales --> Process[Обработка запроса]
    Tech --> Process
    Billing --> Process
    General --> Process
    Process --> Respond[Отправка ответа]
```

<details>
<summary>Примеры входных запросов</summary>

```text
Запрос 1: "Здравствуйте! Хочу узнать про новые тарифы."
Запрос 2: "Не могу оплатить счёт, платеж отклоняется."
Запрос 3: "Как подключить международный роуминг?"
Запрос 4: "Где найти договор оферты?"
```

</details>

<details>
<summary>Системный промпт: LLM routing</summary>

```text
Вы — модель маршрутизации входящих запросов клиентов.
Входные данные:
- Текст запроса клиента: {request}
Задача: определить направление обработки запроса: одно из значений "Продажи", "Техническая поддержка", "Биллинг", "Общие вопросы".
Выход: строка с одним из указанных значений.
```

</details>

<details>
<summary>Системный промпт: LLM обработка запроса</summary>

```text
Вы — модель для обработки клиентских запросов в направлении {direction}.
Входные данные:
- Текст запроса клиента: {request}
Задача: сформировать развернутый и вежливый ответ на запрос в соответствии со спецификой направления.
Выход: текстовый ответ клиенту.
```

</details>

</details>

<details>
<summary>Примеры Web3 workflows</summary>

<details>
<summary>Minting и листинг NFT</summary>

```mermaid
flowchart TD
    Metadata[Ввод метаданных NFT] --> LLMGenerate[LLM: генерация JSON метаданных]
    LLMGenerate --> Sign[Кошелёк: подпись транзакции mint]
    Sign --> Blockchain[Отправка транзакции в блокчейн]
    Blockchain --> Confirm[Подтверждение транзакции]
    Confirm --> LLMDesc[LLM: генерация описания для листинга]
    LLMDesc --> Marketplace[Публикация на маркетплейсе]
    Marketplace --> Notify[Уведомление пользователя]
```

<details>
<summary>Примеры входных данных</summary>

```json
{
  "name": "CryptoKitty #2024",
  "description": "Эксклюзивный NFT с анимированным котиком",
  "image": "https://example.com/cat.gif",
  "attributes": [
    { "trait_type": "rarity", "value": "epic" },
    { "trait_type": "background", "value": "galaxy" }
  ]
}
```

</details>

<details>
<summary>Системные промпты</summary>

<details>
<summary>LLM: генерация JSON метаданных</summary>

```text
Вы — модель для генерации JSON-метаданных NFT в формате ERC-721.
Вход: {name, description, image, attributes}.
Выход: JSON-объект без лишних комментариев.
```

</details>

<details>
<summary>LLM: генерация описания для листинга</summary>

```text
Вы — модель для написания продающих описаний NFT.
Вход: JSON-метаданные NFT.
Задача: сформировать короткое (2–3 предложения), цепляющее описание.
Выход: чистый текст.
```

</details>

</details>
</details>

<details>
<summary>Своп токенов на DEX</summary>

```mermaid
flowchart TD
    UserRequest[Запрос на своп токенов] --> Parse[LLM: парсинг параметров свопа]
    Parse --> Price[Получение курса с оракула]
    Price --> LLMRoute[LLM: выбор оптимального маршрута]
    LLMRoute --> TxGen[Генерация данных транзакции]
    TxGen --> Sign[Кошелёк: подпись транзакции]
    Sign --> SendChain[Отправка транзакции в блокчейн]
    SendChain --> ConfirmTx[Подтверждение транзакции]
    ConfirmTx --> Notify[Уведомление пользователя]
```

<details>
<summary>Примеры входных запросов</summary>

```text
Запрос 1: "Обменять 1.5 ETH на DAI по лучшему курсу."
Запрос 2: "Свопнуть 1000 USDC на USDT при минимальных комиссиях."
```

</details>

<details>
<summary>Системные промпты</summary>

<details>
<summary>LLM: парсинг параметров свопа</summary>

```text
Вы — модель для извлечения параметров свопа из текстового запроса.
Вход: текст запроса.
Задача: вернуть JSON {from_token, to_token, amount}.
```

</details>

<details>
<summary>LLM: выбор оптимального маршрута</summary>

```text
Вы — модель для выбора оптимального маршрута свопа на DEX.
Вход: JSON {from_token, to_token, amount}.
Задача: предложить путь обмена через пулы, минимизируя проскальзывание.
Выход: JSON {route, estimated_gas}.
```

</details>

</details>
</details>

<details>
<summary>Создание предложения в DAO</summary>

```mermaid
flowchart TD
    Idea[Идея пользователя] --> LLMDraft[LLM: черновик текста предложения]
    LLMDraft --> Review[Человек: проверка и правка]
    Review --> LLMFormat[LLM: форматирование под требования DAO]
    LLMFormat --> Submit[Отправка в смарт‑контракт DAO]
    Submit --> Vote[Фаза голосования]
    Vote --> LLMSummary[LLM: сводка результатов голосования]
    LLMSummary --> Publish[Публикация итогов]
```

<details>
<summary>Примеры входных запросов</summary>

```text
Идея 1: "Предложить увеличить пул ликвидности за счёт 5% комиссии транзакций."
Идея 2: "Внедрить программу вознаграждения активных участников DAO."
```

</details>

<details>
<summary>Системные промпты</summary>

<details>
<summary>LLM: черновик текста предложения</summary>

```text
Вы — модель для преобразования идеи в формальное предложение DAO.
Вход: текст идеи.
Задача: сформировать JSON {title, description}.
```

</details>

<details>
<summary>LLM: форматирование под требования DAO</summary>

```text
Вы — модель для форматирования черновика согласно шаблону DAO.
Вход: JSON {title, description}.
Требования: title до 100 символов, description до 1000 символов.
Выход: JSON {title, description}.
```

</details>

<details>
<summary>LLM: сводка результатов голосования</summary>

```text
Вы — модель для создания итоговой сводки голосования.
Вход: список голосов [{voter, vote}].
Задача: подсчитать результаты и сформулировать вывод.
Выход: текстовая сводка.
```

</details>

</details>
</details>

<details>
<summary>Автоматизированный аудит смарт‑контрактов</summary>

```mermaid
flowchart TD
    Source[Исходный код смарт‑контракта] --> LLMAnalyze[LLM: анализ безопасности]
    LLMAnalyze --> Report[LLM: генерация отчёта об уязвимостях]
    Report --> HumanReview[Человек: проверка отчёта]
    HumanReview --> Fixes[Внесение исправлений]
    Fixes --> ReAnalyze[LLM: повторный анализ]
    ReAnalyze --> FinalReport[Итоговый отчёт]
```

<details>
<summary>Примеры входных данных</summary>

```solidity
// SPDX-License-Identifier: MIT
pragma solidity ^0.8.0;

contract SimpleToken {
    mapping(address => uint256) public balances;
    function mint(address to, uint256 amount) public {
        balances[to] += amount;
    }
}
```

</details>

<details>
<summary>Системные промпты</summary>

<details>
<summary>LLM: анализ безопасности</summary>

```text
Вы — модель для анализа безопасности смарт‑контрактов.
Вход: исходный код контракта.
Задача: выявить уязвимости (overflow, reentrancy и т.д.) и дать рекомендации.
Выход: JSON [{issue, severity, recommendation}].
```

</details>

<details>
<summary>LLM: генерация отчёта об уязвимостях</summary>

```text
Вы — модель для составления отчёта на основе анализа уязвимостей.
Вход: результаты анализа безопасности.
Задача: написать детальный markdown-отчёт с описанием каждой проблемы и рекомендациями.
Выход: markdown.
```

</details>

</details>
</details>

</details>

