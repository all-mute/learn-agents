---
sidebar_label: Chatbots y memoria a corto plazo
---

# Chatbots y memoria a corto plazo

# Pasos

### 1. Chatbots

[Explora la diferencia entre chatbots y otras cosas](https://excalidraw.com/#json=zjh38Ls_XMRTsUO60aur5,2ieU4682rDovB05fL_KgOw)

### 2. Estudiamos la memoria a corto plazo

¬øQu√© hacer si un usuario interact√∫a con tu bot por d√©cima vez?
    - Primero, debido al gran historial de mensajes, el LLM sigue peor las √∫ltimas instrucciones.
    - Segundo, cada solicitud posterior costar√° m√°s (si utilizamos un LLM propietario, todos los tokens de entrada se facturan).

:::tip
¬°Simplemente lee ambos art√≠culos, mira las im√°genes, lo principal es entender los conceptos!

Si has estudiado cuidadosamente la API de OpenAI, estos art√≠culos te resultar√°n sencillos y comprensibles.
:::

[C√≥mo manejamos el historial de mensajes](https://langchain-ai.github.io/langgraph/concepts/memory/#summarizing-past-conversations)

[Comparaci√≥n de diferentes enfoques](https://www.pinecone.io/learn/series/langchain/langchain-expression-language/)

:::warning contras
Al eliminar/resumir mensajes, perdemos informaci√≥n √∫til.

Por ejemplo, los primeros mensajes que vamos a eliminar pueden contener las especificaciones t√©cnicas del usuario, y al eliminar/resumir, se perder√°n detalles.
:::

#### Estrategias principales para gestionar el historial de mensajes

1. **Recorte por n√∫mero de tokens (`max_tokens`)**  
   Permite limitar el historial de mensajes para que su n√∫mero total de tokens no exceda un valor dado. Esto es especialmente √∫til para cumplir con las limitaciones de la ventana de contexto del modelo.

2. **Recorte por n√∫mero de mensajes (`max_messages`)**  
   Limita el historial a un cierto n√∫mero de mensajes m√°s recientes, eliminando los m√°s antiguos.

#### Par√°metros adicionales para configurar el recorte

- **`strategy="last"`**  
  Guarda los mensajes m√°s recientes, eliminando los m√°s antiguos. Esta es la estrategia est√°ndar para mantener el contexto actual.

- **`include_system=True`**  
  Garantiza la conservaci√≥n del `SystemMessage`, que normalmente contiene instrucciones importantes para el modelo. ([How to trim messages | ü¶úÔ∏è LangChain](https://python.langchain.com/docs/how_to/trim_messages/?utm_source=chatgpt.com))

- **`start_on="human"` y `ends_on=("human", "tool")`**  
  Aseguran la estructura correcta del historial de mensajes, comenzando con un mensaje del usuario y terminando con un mensaje del usuario o de la herramienta.

#### Ejemplos de uso

Para recortar el historial de mensajes por n√∫mero de tokens, conservando el mensaje del sistema y los √∫ltimos mensajes del usuario, puedes utilizar el siguiente c√≥digo:

```python
from langchain_core.messages import trim_messages

trimmed_history = trim_messages(
    messages=chat_history,
    max_tokens=1000,
    strategy="last",
    include_system=True,
    start_on="human",
    ends_on=("human", "tool")
)
```

Puedes encontrar m√°s informaci√≥n sobre las funciones y los par√°metros de `trim_messages` en la documentaci√≥n oficial de LangChain:

- [How to trim messages](https://python.langchain.com/docs/how_to/trim_messages/)

#### T√©cnicas avanzadas:

- Podemos utilizar varias memorias a corto plazo, por ejemplo:
    - una para almacenar el historial de mensajes - se ubicar√° en los propios mensajes
    - una segunda para almacenar informaci√≥n sobre el usuario (por ejemplo, sus preferencias) - se ubicar√° en el mensaje del sistema
    - una tercera para almacenar la tarea del usuario - se ubicar√° en el mensaje del sistema
- Podemos hacer retrieve de los mensajes eliminados si es necesario (retrieve lo estudiaremos en el futuro [m√≥dulo](./rag/index))
